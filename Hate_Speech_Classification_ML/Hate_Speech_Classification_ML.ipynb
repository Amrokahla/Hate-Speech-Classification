{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-6lrKz6orxT"
   },
   "source": [
    "### Import used libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySsIPBRiorxK"
   },
   "source": [
    "**Dataset**\n",
    "labeled datasset collected from twitter (Lab 1 - Hate Speech.tsv)\n",
    "\n",
    "**Objective**\n",
    "classify tweets containing hate speech from other tweets. <br>\n",
    "0 -> no hate speech <br>\n",
    "1 -> contains hate speech <br>\n",
    "\n",
    "\n",
    "**Evaluation metric**\n",
    "macro f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXUPo3g4orxV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re, html, emoji\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import gensim.downloader as api\n",
    "from sklearn.metrics import  f1_score\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.base import TransformerMixin\n",
    "from scipy.sparse import issparse\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fG8MkuvjorxX"
   },
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Note: search how to load the data from tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYeqhp66orxY"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Hate Speech.tsv\", sep= \"\\t\", index_col='id')\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['label'].value_counts())\n",
    "print(f\"\\nclass distribution {data['label'].value_counts()[1]/data['label'].value_counts()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good practice to split the data before EDA helps maintain the integrity of the machine learning process, prevents data leakage, simulates real-world scenarios more accurately, and ensures reliable model performance evaluation on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(data))\n",
    "test_size = val_size = int(0.15 * len(data))\n",
    "print(f\"train_size: {train_size}\\ntest_size: {test_size}\\nval_size: {val_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:train_size]\n",
    "val = data[train_size:train_size+val_size]\n",
    "test = data[train_size+val_size:]\n",
    "\n",
    "print(f\"train class distribution\\n{train['label'].value_counts()}\")\n",
    "print(f\"class distribution {train['label'].value_counts()[1]/train['label'].value_counts()[0]}\\n\")\n",
    "print(f\"val class distribution\\n{val['label'].value_counts()}\")\n",
    "print(f\"class distribution {val['label'].value_counts()[1]/val['label'].value_counts()[0]}\\n\")\n",
    "print(f\"test class distribution\\n{test['label'].value_counts()}\")\n",
    "print(f\"class distribution {test['label'].value_counts()[1]/test['label'].value_counts()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class distribution across splits is maintained as original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqWVKi_GorxZ"
   },
   "source": [
    "### EDA on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1zxJpFxorxa"
   },
   "source": [
    "- check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVEttSujorxa"
   },
   "outputs": [],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwjbzVaIorxb"
   },
   "source": [
    "- check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_FlBWISorxb"
   },
   "outputs": [],
   "source": [
    "train.duplicated(keep =\"first\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjIBFc35orxc"
   },
   "source": [
    "- show a representative sample of data texts to find out required preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGFKzSCRorxc"
   },
   "outputs": [],
   "source": [
    "def get_random_sample(data = None):\n",
    "    n = random.randint(0,22074)\n",
    "    print(data.iloc[[n],1].item())\n",
    "\n",
    "for i in range(20):\n",
    "    print(f\"sample {i}\")\n",
    "    get_random_sample(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqdSUtbdorxd"
   },
   "source": [
    "- check dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBHrSvXhorxd"
   },
   "outputs": [],
   "source": [
    "print(data['label'].value_counts())\n",
    "print(f\"\\nclass distribution {data['label'].value_counts()[1]/data['label'].value_counts()[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = train['label'].value_counts().reset_index()\n",
    "label_counts.columns = ['label', 'count']\n",
    "\n",
    "sns.barplot(data=label_counts, x='label', y='count', hue='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyJkqK9gorxe"
   },
   "source": [
    "### Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Extra: use custom scikit-learn Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using custom transformers in scikit-learn provides flexibility, reusability, and control over the data transformation process, allowing you to seamlessly integrate with scikit-learn's pipelines, enabling you to combine multiple preprocessing steps and modeling into a single workflow. This makes your code more modular, readable, and easier to maintain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### link: https://www.andrewvillazon.com/custom-scikit-learn-transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My custom_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVjzzLhworxe"
   },
   "outputs": [],
   "source": [
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, text_column='tweet'):\n",
    "        self.text_column = text_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[self.text_column] = X[self.text_column].apply(self.clean_text)\n",
    "        return X\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = html.unescape(text)\n",
    "        text = re.sub(r'@\\w+', '', text)\n",
    "        text = re.sub(r'#(\\w+)', lambda m: re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', m.group(1)), text)\n",
    "        text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "        text = emoji.demojize(text)\n",
    "        text = re.sub(r':([a-zA-Z_]+):', r'\\1', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\d+', '<NUM>', text)\n",
    "        text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s<>]', '', text)\n",
    "        text = re.sub(r'_+', ' ', text).strip()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vectorizer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, method=\"BOW\", ngram_range=(1, 1), vector_size=300, text_column=\"tweet\", max_len=100, num_words=1000):\n",
    "        self.method = method\n",
    "        self.ngram_range = ngram_range\n",
    "        self.vector_size = vector_size\n",
    "        self.text_column = text_column\n",
    "        self.max_len = max_len\n",
    "        self.num_words = num_words\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        texts = X[self.text_column].values\n",
    "        method = self.method.upper()\n",
    "\n",
    "        if method == \"BOW\":\n",
    "            self.vectorizer_ = CountVectorizer()\n",
    "            self.vectorizer_.fit(texts)\n",
    "\n",
    "        elif method in [\"TFIDF\", \"NGRAM\"]:\n",
    "            self.vectorizer_ = TfidfVectorizer(ngram_range=self.ngram_range)\n",
    "            self.vectorizer_.fit(texts)\n",
    "\n",
    "        elif method == \"WORD2VEC\":\n",
    "            self.embeddings_ = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "        elif method == \"GLOVE\":\n",
    "            self.embeddings_ = api.load(\"glove-wiki-gigaword-300\")\n",
    "\n",
    "        elif method == \"FASTTEXT\":\n",
    "            self.embeddings_ = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "        elif method == \"CNN\":\n",
    "            self.tokenizer_ = Tokenizer(num_words=self.num_words)\n",
    "            self.tokenizer_.fit_on_texts(texts)\n",
    "            self._build_cnn()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown vectorizer method: {self.method}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        texts = X[self.text_column].values\n",
    "        method = self.method.upper()\n",
    "\n",
    "        if method in [\"BOW\", \"TFIDF\", \"NGRAM\"]:\n",
    "            return self.vectorizer_.transform(texts)\n",
    "\n",
    "        elif method in [\"WORD2VEC\", \"GLOVE\", \"FASTTEXT\"]:\n",
    "            return np.vstack([self._avgvec(text) for text in texts])\n",
    "\n",
    "        elif method == \"CNN\":\n",
    "            sequences = self.tokenizer_.texts_to_sequences(texts)\n",
    "            padded = pad_sequences(sequences, maxlen=self.max_len)\n",
    "            return self.cnn_model_.predict(padded, verbose=0)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown vectorizer method: {self.method}\")\n",
    "\n",
    "    def _avgvec(self, text):\n",
    "        tokens = text.split()\n",
    "        vectors = [self.embeddings_[word] for word in tokens if word in self.embeddings_]\n",
    "        if not vectors:\n",
    "            return np.zeros(self.vector_size)\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    def _build_cnn(self):\n",
    "        self.cnn_model_ = Sequential([\n",
    "            Embedding(input_dim=self.num_words, output_dim=128, input_length=self.max_len),\n",
    "            Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "            GlobalMaxPooling1D(),\n",
    "            Dense(100, activation='relu')\n",
    "        ])\n",
    "        self.cnn_model_.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    \n",
    "class ToDense(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.toarray() if issparse(X) else X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9BhRQbYorxf"
   },
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', TextCleaner()),\n",
    "    ('vectorizing', Vectorizer(method='bow')),\n",
    "    ('model', model),\n",
    "    ])\n",
    "\n",
    "pipeline.fit(train, train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85JlkIQXorxg"
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation metric:**\n",
    "macro f1 score\n",
    "\n",
    "Macro F1 score is a useful metric in scenarios where you want to evaluate the overall performance of a multi-class classification model, **particularly when the classes are imbalanced**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipeline.predict(test)\n",
    "macro_f1 = f1_score(test['label'], pred, average='macro')\n",
    "print(f\"Macro F1: {macro_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhVFUaIcorxh"
   },
   "source": [
    "### Enhancement\n",
    "\n",
    "- Using different vectorizers with different hyperparameters\n",
    "- Trying different ML models and doing hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizes = [\"BOW\", \"TFIDF\", \"WORD2VEC\", \"GLOVE\", \"FASTTEXT\", \"CNN\"]\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "for v in vectorizes:\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', TextCleaner()),\n",
    "        ('Vectorizing', Vectorizer(method= v)),\n",
    "        ('model', model),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train, train[\"label\"])\n",
    "\n",
    "    pred = pipeline.predict(test)\n",
    "    macro_f1 = f1_score(test['label'], pred, average='macro')\n",
    "    scores[\"RandomForest-\"+v] = macro_f1\n",
    "    print(f\"RandomForestClassifier with {v} status: Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "\n",
    "for v in vectorizes:\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', TextCleaner()),\n",
    "        ('Vectorizing', Vectorizer(method= v)),\n",
    "        ('model', model),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train, train[\"label\"])\n",
    "\n",
    "    pred = pipeline.predict(test)\n",
    "    scores[\"GradientBoosting-\"+v] = macro_f1\n",
    "    print(f\"GradientBoostingClassifier with {v} status: Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "for v in vectorizes:\n",
    "    pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', TextCleaner()),\n",
    "    ('vectorizing', Vectorizer(method=v)),\n",
    "    ('to_dense', ToDense()),\n",
    "    ('model', model),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train, train[\"label\"])\n",
    "\n",
    "    pred = pipeline.predict(test)\n",
    "    scores[\"NaiveBayes-\"+v] = macro_f1\n",
    "    print(f\"GaussianNB with {v} status: Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Descision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(scores.keys(), scores.values())\n",
    "\n",
    "plt.title('Models-Vectorizers MaCro F1 score', fontsize=14)\n",
    "plt.ylabel('Macro F1 score', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.xticks(rotation=40)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model : __Random Forest__<br/>vectorizer : __TFIDF__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4h1Danvorxh"
   },
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', TextCleaner()),\n",
    "    ('Vectorizing', Vectorizer(method=\"TFIDF\", ngram_range=(1,1))),\n",
    "    ('model', model),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': [100, 200, 400],\n",
    "    'model__max_depth': [None, 10, 20, 30],\n",
    "    'model__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=3, n_jobs=-1,  verbose=2)\n",
    "grid_search.fit(train, train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDsCjdqsorxi"
   },
   "outputs": [],
   "source": [
    "pred = grid_search.predict(test)\n",
    "macro_f1 = f1_score(test['label'], pred, average='macro')\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "print(f\"Macro F1: {macro_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion and final results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Data has a big imbalance in the classes\n",
    "2. Different Vectorization techniques gives different scores based on the problem\n",
    "3. TFIDF with Random Forest gives the best Macro F1 score\n",
    "4. ML Models can handle simple NLP tasks"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
